{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T13:44:19.483986Z",
     "iopub.status.busy": "2025-07-09T13:44:19.483801Z",
     "iopub.status.idle": "2025-07-09T13:44:30.477070Z",
     "shell.execute_reply": "2025-07-09T13:44:30.476290Z",
     "shell.execute_reply.started": "2025-07-09T13:44:19.483970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T13:44:30.479405Z",
     "iopub.status.busy": "2025-07-09T13:44:30.478580Z",
     "iopub.status.idle": "2025-07-09T13:44:30.504021Z",
     "shell.execute_reply": "2025-07-09T13:44:30.503458Z",
     "shell.execute_reply.started": "2025-07-09T13:44:30.479385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        # load raw object; could be dict, list, or saved TaskDataset\n",
    "        data = torch.load(data_path, weights_only=False)\n",
    "\n",
    "        # If it's already a TaskDataset instance, reuse its attributes\n",
    "        if isinstance(data, TaskDataset):\n",
    "            self.ids = data.ids\n",
    "            self.imgs = data.imgs\n",
    "            self.labels = data.labels\n",
    "\n",
    "        # If it's a dict with keys 'ids','imgs','labels', unpack it:\n",
    "        elif isinstance(data, dict) and all(k in data for k in ('ids','imgs','labels')):\n",
    "            self.ids = list(data['ids'])\n",
    "            self.imgs = list(data['imgs'])\n",
    "            self.labels = list(data['labels'])\n",
    "\n",
    "        # If it's a list of triplets, unzip them:\n",
    "        elif isinstance(data, list) and len(data) > 0 and isinstance(data[0], (list, tuple)) and len(data[0]) == 3:\n",
    "            self.ids, self.imgs, self.labels = map(list, zip(*data))\n",
    "\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unrecognized Train.pt format: got {type(data)}\")\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "def fgsm_attack(model, loss_fn, images, labels, epsilon):\n",
    "    \"\"\"FGSM attack implementation\"\"\"\n",
    "    images = images.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Zero gradients\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Calculate gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Create adversarial examples\n",
    "    grad_sign = images.grad.data.sign()\n",
    "    adv_images = images + epsilon * grad_sign\n",
    "    \n",
    "    return torch.clamp(adv_images, 0, 1).detach()\n",
    "\n",
    "\n",
    "def pgd_attack(model, loss_fn, images, labels, epsilon, alpha, iters):\n",
    "    \"\"\"PGD attack implementation\"\"\"\n",
    "    orig_images = images.clone().detach()\n",
    "    \n",
    "    # Start with random noise\n",
    "    delta = torch.zeros_like(images).uniform_(-epsilon, epsilon)\n",
    "    delta = torch.clamp(delta, 0-images, 1-images)\n",
    "    \n",
    "    for _ in range(iters):\n",
    "        delta.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(orig_images + delta)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update delta\n",
    "        grad = delta.grad.detach()\n",
    "        delta = delta + alpha * grad.sign()\n",
    "        \n",
    "        # Project back to epsilon ball\n",
    "        delta = torch.clamp(delta, -epsilon, epsilon)\n",
    "        delta = torch.clamp(delta, 0-orig_images, 1-orig_images)\n",
    "        delta = delta.detach()\n",
    "    \n",
    "    return (orig_images + delta).detach()\n",
    "\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, loss_fn, epoch, total_epochs, \n",
    "                epsilon, alpha, pgd_iters):\n",
    "    \"\"\"Improved training function with much more conservative adversarial training\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Much more conservative curriculum to maintain clean accuracy\n",
    "    if epoch <= 20:\n",
    "        # First 20 epochs: only clean data to establish strong baseline\n",
    "        clean_ratio = 1.0\n",
    "        current_epsilon = 0.0\n",
    "        use_adv = False\n",
    "    elif epoch <= 50:\n",
    "        # Next 30 epochs: very gradually introduce weak adversarial examples\n",
    "        progress = (epoch - 20) / 30.0\n",
    "        clean_ratio = 0.9 - 0.1 * progress  # 0.9 -> 0.8 (always favor clean)\n",
    "        current_epsilon = epsilon * (0.1 + 0.3 * progress)  # 0.1*eps -> 0.4*eps\n",
    "        use_adv = True\n",
    "    elif epoch <= 80:\n",
    "        # Next 30 epochs: gradually increase adversarial strength\n",
    "        progress = (epoch - 50) / 30.0\n",
    "        clean_ratio = 0.8 - 0.05 * progress  # 0.8 -> 0.75 (still favor clean)\n",
    "        current_epsilon = epsilon * (0.4 + 0.4 * progress)  # 0.4*eps -> 0.8*eps\n",
    "        use_adv = True\n",
    "    else:\n",
    "        # Final epochs: full strength but still heavily favor clean\n",
    "        clean_ratio = 0.75  # Always keep 75% clean examples\n",
    "        current_epsilon = epsilon\n",
    "        use_adv = True\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{total_epochs}\")\n",
    "    \n",
    "    for batch_idx, (_, imgs, labels) in enumerate(train_bar):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if not use_adv:\n",
    "            # Clean training only\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "        else:\n",
    "            # Mixed training with heavy emphasis on clean examples\n",
    "            clean_size = int(batch_size * clean_ratio)\n",
    "            \n",
    "            # Ensure we always have clean examples\n",
    "            if clean_size == 0:\n",
    "                clean_size = max(1, batch_size // 2)\n",
    "            \n",
    "            # Clean examples\n",
    "            clean_imgs = imgs[:clean_size]\n",
    "            clean_labels = labels[:clean_size]\n",
    "            \n",
    "            # Adversarial examples (only if we have remaining samples)\n",
    "            adv_imgs = imgs[clean_size:]\n",
    "            adv_labels = labels[clean_size:]\n",
    "            \n",
    "            all_imgs = [clean_imgs]\n",
    "            all_labels = [clean_labels]\n",
    "            \n",
    "            # Add adversarial examples only if we have any\n",
    "            if len(adv_imgs) > 0:\n",
    "                # Use only FGSM for first part of adversarial training\n",
    "                if epoch <= 60:\n",
    "                    # Only FGSM to start\n",
    "                    fgsm_imgs = fgsm_attack(model, loss_fn, adv_imgs, adv_labels, current_epsilon)\n",
    "                    all_imgs.append(fgsm_imgs)\n",
    "                    all_labels.append(adv_labels)\n",
    "                else:\n",
    "                    # Mix FGSM and PGD later\n",
    "                    split_point = len(adv_imgs) // 2\n",
    "                    \n",
    "                    # FGSM examples\n",
    "                    if split_point > 0:\n",
    "                        fgsm_imgs = fgsm_attack(model, loss_fn, adv_imgs[:split_point], \n",
    "                                              adv_labels[:split_point], current_epsilon)\n",
    "                        all_imgs.append(fgsm_imgs)\n",
    "                        all_labels.append(adv_labels[:split_point])\n",
    "                    \n",
    "                    # PGD examples (fewer iterations to be less aggressive)\n",
    "                    if len(adv_imgs) - split_point > 0:\n",
    "                        pgd_imgs = pgd_attack(model, loss_fn, adv_imgs[split_point:], \n",
    "                                            adv_labels[split_point:], current_epsilon, \n",
    "                                            alpha, max(3, pgd_iters // 3))  # Reduced iterations\n",
    "                        all_imgs.append(pgd_imgs)\n",
    "                        all_labels.append(adv_labels[split_point:])\n",
    "            \n",
    "            # Combine all examples\n",
    "            combined_imgs = torch.cat(all_imgs, dim=0)\n",
    "            combined_labels = torch.cat(all_labels, dim=0)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(combined_imgs)\n",
    "            loss = loss_fn(outputs, combined_labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # More conservative gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            if use_adv:\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(combined_labels).sum().item()\n",
    "                total_samples += combined_labels.size(0)\n",
    "            else:\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{correct/total_samples:.4f}',\n",
    "            'eps': f'{current_epsilon:.4f}',\n",
    "            'clean_ratio': f'{clean_ratio:.2f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate_model(model, device, data_loader, loss_fn, epsilon, alpha, pgd_iters):\n",
    "    \"\"\"Evaluate model on clean, FGSM, and PGD examples\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    clean_correct = 0\n",
    "    fgsm_correct = 0\n",
    "    pgd_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    eval_bar = tqdm(data_loader, desc=\"Evaluating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _, imgs, labels in eval_bar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            batch_size = imgs.size(0)\n",
    "            \n",
    "            # Clean accuracy\n",
    "            clean_outputs = model(imgs)\n",
    "            clean_preds = clean_outputs.argmax(dim=1)\n",
    "            clean_correct += clean_preds.eq(labels).sum().item()\n",
    "            \n",
    "            total += batch_size\n",
    "            \n",
    "            eval_bar.set_postfix({\n",
    "                'clean': f'{clean_correct/total:.4f}',\n",
    "                'total': total\n",
    "            })\n",
    "    \n",
    "    # Reset for adversarial evaluation\n",
    "    model.eval()\n",
    "    fgsm_correct = 0\n",
    "    pgd_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    eval_bar = tqdm(data_loader, desc=\"Evaluating Adversarial\")\n",
    "    \n",
    "    for _, imgs, labels in eval_bar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.size(0)\n",
    "        \n",
    "        # FGSM attack\n",
    "        fgsm_imgs = fgsm_attack(model, loss_fn, imgs, labels, epsilon)\n",
    "        with torch.no_grad():\n",
    "            fgsm_outputs = model(fgsm_imgs)\n",
    "            fgsm_preds = fgsm_outputs.argmax(dim=1)\n",
    "            fgsm_correct += fgsm_preds.eq(labels).sum().item()\n",
    "        \n",
    "        # PGD attack\n",
    "        pgd_imgs = pgd_attack(model, loss_fn, imgs, labels, epsilon, alpha, pgd_iters)\n",
    "        with torch.no_grad():\n",
    "            pgd_outputs = model(pgd_imgs)\n",
    "            pgd_preds = pgd_outputs.argmax(dim=1)\n",
    "            pgd_correct += pgd_preds.eq(labels).sum().item()\n",
    "        \n",
    "        total += batch_size\n",
    "        \n",
    "        eval_bar.set_postfix({\n",
    "            'fgsm': f'{fgsm_correct/total:.4f}',\n",
    "            'pgd': f'{pgd_correct/total:.4f}',\n",
    "            'total': total\n",
    "        })\n",
    "    \n",
    "    clean_acc = clean_correct / len(data_loader.dataset)\n",
    "    fgsm_acc = fgsm_correct / total\n",
    "    pgd_acc = pgd_correct / total\n",
    "    \n",
    "    return clean_acc, fgsm_acc, pgd_acc\n",
    "\n",
    "\n",
    "def submit_model(token, model_name, model_path):\n",
    "    \"\"\"Submit model to evaluation server\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://34.122.51.94:9090/robustness\",\n",
    "            files={\"file\": open(model_path, \"rb\")},\n",
    "            headers={\"token\": token, \"model-name\": model_name}\n",
    "        )\n",
    "        print(\"Submission response:\", response.json())\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Submission failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T13:44:30.504817Z",
     "iopub.status.busy": "2025-07-09T13:44:30.504620Z",
     "iopub.status.idle": "2025-07-09T15:39:06.586407Z",
     "shell.execute_reply": "2025-07-09T15:39:06.585591Z",
     "shell.execute_reply.started": "2025-07-09T13:44:30.504803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Configuration\n",
    "    data_path = '/kaggle/input/tml-t3/Train.pt'\n",
    "    model_name = 'resnet34'\n",
    "    batch_size = 128\n",
    "    epochs = 100\n",
    "    lr = 0.01  # Lower learning rate for more stable training\n",
    "    epsilon = 8/255\n",
    "    alpha = 2/255\n",
    "    pgd_iters = 10\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Epsilon: {epsilon:.4f}, Alpha: {alpha:.4f}, PGD iters: {pgd_iters}\")\n",
    "    \n",
    "    # More conservative data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB') if hasattr(img, 'convert') else img),\n",
    "        transforms.RandomHorizontalFlip(p=0.3),  # Reduced probability\n",
    "        transforms.RandomCrop(32, padding=2),    # Reduced padding\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB') if hasattr(img, 'convert') else img),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        ids, imgs, labels = zip(*batch)\n",
    "        imgs = torch.stack(imgs, dim=0)\n",
    "        labels = torch.tensor(labels)\n",
    "        return list(ids), imgs, labels\n",
    "\n",
    "    # Create train/validation split\n",
    "    full_dataset = TaskDataset(data_path, transform=train_transform)\n",
    "    train_size = int(0.9 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Create separate dataset for validation with different transform\n",
    "    val_dataset_clean = TaskDataset(data_path, transform=val_transform)\n",
    "    val_indices = val_dataset.indices\n",
    "    val_subset = torch.utils.data.Subset(val_dataset_clean, val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Model setup\n",
    "    model = getattr(models, model_name)(weights='DEFAULT')\n",
    "    \n",
    "    # Replace final layer with better initialization\n",
    "    if hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "        # Xavier initialization for better stability\n",
    "        nn.init.xavier_uniform_(model.fc.weight)\n",
    "        nn.init.constant_(model.fc.bias, 0)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    # More conservative optimizer settings\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    \n",
    "    # More gradual learning rate schedule\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 85], gamma=0.2)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training setup\n",
    "    best_score = 0.0\n",
    "    os.makedirs('out/models', exist_ok=True)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_clean_acc': [],\n",
    "        'val_fgsm_acc': [],\n",
    "        'val_pgd_acc': [],\n",
    "        'combined_score': []\n",
    "    }\n",
    "\n",
    "    print(\"Starting conservative adversarial training...\")\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\n=== Epoch {epoch}/{epochs} ===\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, device, train_loader, optimizer, loss_fn, epoch, epochs,\n",
    "            epsilon, alpha, pgd_iters\n",
    "        )\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log training progress\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        if epoch % 5 == 0 or epoch == epochs or epoch <= 20:\n",
    "            print(\"Evaluating on validation set...\")\n",
    "            clean_acc, fgsm_acc, pgd_acc = evaluate_model(\n",
    "                model, device, val_loader, loss_fn, epsilon, alpha, pgd_iters\n",
    "            )\n",
    "            \n",
    "            # Heavily weighted towards clean accuracy\n",
    "            combined_score = 0.7 * clean_acc + 0.2 * fgsm_acc + 0.1 * pgd_acc\n",
    "            \n",
    "            history['val_clean_acc'].append(clean_acc)\n",
    "            history['val_fgsm_acc'].append(fgsm_acc)\n",
    "            history['val_pgd_acc'].append(pgd_acc)\n",
    "            history['combined_score'].append(combined_score)\n",
    "            \n",
    "            print(f\"Val Clean Acc: {clean_acc:.4f}\")\n",
    "            print(f\"Val FGSM Acc:  {fgsm_acc:.4f}\")\n",
    "            print(f\"Val PGD Acc:   {pgd_acc:.4f}\")\n",
    "            print(f\"Combined Score: {combined_score:.4f}\")\n",
    "            \n",
    "            # Save best model with strong preference for clean accuracy\n",
    "            if combined_score > best_score and clean_acc > 0.60:  # Ensure clean acc is high\n",
    "                best_score = combined_score\n",
    "                torch.save(model.state_dict(), f\"out/models/{model_name}_best.pt\")\n",
    "                print(f\"ðŸŽ¯ New best model saved! Score: {combined_score:.4f}\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n=== Final Evaluation ===\")\n",
    "    clean_acc, fgsm_acc, pgd_acc = evaluate_model(\n",
    "        model, device, val_loader, loss_fn, epsilon, alpha, pgd_iters\n",
    "    )\n",
    "    final_combined_score = 0.7 * clean_acc + 0.2 * fgsm_acc + 0.1 * pgd_acc\n",
    "    \n",
    "    print(f\"Final Clean Accuracy: {clean_acc:.4f}\")\n",
    "    print(f\"Final FGSM Accuracy:  {fgsm_acc:.4f}\")\n",
    "    print(f\"Final PGD Accuracy:   {pgd_acc:.4f}\")\n",
    "    print(f\"Final Combined Score: {final_combined_score:.4f}\")\n",
    "    print(f\"Best Combined Score:  {best_score:.4f}\")\n",
    "    \n",
    "    # Save final model and history\n",
    "    torch.save(model.state_dict(), f\"out/models/{model_name}_final.pt\")\n",
    "    with open(f\"out/models/training_history.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    \n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7772347,
     "sourceId": 12329813,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
